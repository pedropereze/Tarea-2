{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "Integrantes:\n",
    "* Juan Maulén \n",
    "* Pedro Pérez\n",
    "* Tomás Rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:02:17.697434Z",
     "start_time": "2020-07-05T05:02:15.990418Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import DatasetFolder\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:02:17.732741Z",
     "start_time": "2020-07-05T05:02:17.709438Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_rotation(im, theta):\n",
    "    theta = random.uniform(*theta)\n",
    "    return im.rotate(theta)\n",
    "\n",
    "def random_flip(im):\n",
    "    if bool(random.getrandbits(1)):\n",
    "        im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return im\n",
    "    \n",
    "def normalize_im(im):\n",
    "    im = np.asarray(im)\n",
    "    \n",
    "def loader(path):\n",
    "    transformation = ToTensor()\n",
    "    \n",
    "    im = Image.open(path).resize((224, 224))  # escalamiento de la imagen\n",
    "    im = random_flip(im)  # reflexion de la imagen\n",
    "    im = random_rotation(im, (-20, 20))  # rotacion aleatoria de la imagen\n",
    "    \n",
    "    \n",
    "    tensor = transformation(im)  # se transforma la imagen a un tensor\n",
    "    if tensor.shape[0] == 1:\n",
    "        tensor = tensor.repeat(3, 1, 1)\n",
    "    \n",
    "    rand_tensor = (1.5 - 1.2) * torch.rand((3, 224, 224)) + 1.2\n",
    "    return tensor * rand_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:29:15.075045Z",
     "start_time": "2020-07-05T05:29:15.005550Z"
    }
   },
   "outputs": [],
   "source": [
    "train_folder = DatasetFolder('./chest_xray/train', loader=loader, extensions='.jpeg')\n",
    "# distribución real\n",
    "test_folder = DatasetFolder('./chest_xray/test', loader=loader, extensions='.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(train_folder, test_folder):\n",
    "    train_folder_x, train_folder_y = np.unique(train_folder.targets, return_counts=True)\n",
    "    test_folder_x, test_folder_y = np.unique(test_folder.targets, return_counts=True)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar([\"'NORMAL' train\",\"'PNEUMONIA' train\"], \n",
    "            train_folder_y)\n",
    "    plt.bar([\"'NORMAL' test\",\"'PNEUMONIA' test\"], \n",
    "            test_folder_y)\n",
    "\n",
    "    p_normal_train = train_folder_y[0] / train_folder_y.sum()\n",
    "    p_pneumonia_train = train_folder_y[1] / train_folder_y.sum()\n",
    "    p_normal_test = test_folder_y[0] / test_folder_y.sum()\n",
    "    p_pneumonia_test = test_folder_y[1] / test_folder_y.sum()\n",
    "\n",
    "\n",
    "    plt.text(-.1, train_folder_y[0] + 15,\n",
    "             '{:.2f}%'.format(p_normal_train * 100))\n",
    "\n",
    "    plt.text(-.1 + 1, train_folder_y[1] + 15,\n",
    "             '{:.2f}%'.format(p_pneumonia_train * 100))\n",
    "\n",
    "    plt.text(-.1 + 2, test_folder_y[0] + 15,\n",
    "             '{:.2f}%'.format(p_normal_test * 100))\n",
    "\n",
    "    plt.text(-.1 + 3, test_folder_y[1] + 15,\n",
    "             '{:.2f}%'.format(p_pneumonia_test * 100))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:02:18.803757Z",
     "start_time": "2020-07-05T05:02:17.912552Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogram(train_folder, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "n_test =  int(len(data_train) * .2)  \n",
    "n_train = len(data_train) - n_test\n",
    "train, test = torch.utils.data.random_split(data_train, [n_train, n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(data_train.targets)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicarMuestreoDePrueba(torch.utils.data.Sampler):\n",
    "    \n",
    "    def __init__(self, etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        self.etiquetas_prueba = etiquetas_prueba\n",
    "        self.indices_val = indices_val\n",
    "        self.etiquetas_val = etiquetas_val\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # {'NORMAL': 0, 'PNEUMONIA': 1}\n",
    "        clases_prueba, frecuencias_prueba = np.unique(self.etiquetas_prueba, \n",
    "                                                      return_counts=True)\n",
    "        \n",
    "        p_normal_deseada = frecuencias_prueba[0] / frecuencias_prueba.sum()\n",
    "        \n",
    "        indices_val_0 = self.indices_val[np.where(np.array(etiquetas_val)==0)]\n",
    "        indices_val_1 = self.indices_val[np.where(np.array(etiquetas_val)==1)]\n",
    "        \n",
    "        n_0 = len(indices_val_0)\n",
    "        n_1 = int(n_0 / p_normal_deseada - n_0)\n",
    "        \n",
    "        indices_val_1 = np.random.choice(indices_val_1, n_1)\n",
    "        \n",
    "        lista_con_indices = indices_val_0.tolist() + indices_val_1.tolist()\n",
    "        return iter(lista_con_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices\n",
    "# train_targets\n",
    "# test_indices\n",
    "# test_targets\n",
    "# son sub conjuntos de data_train\n",
    "\n",
    "train_indices, train_targets = train.indices, train.dataset.targets\n",
    "test_indices, test_targets = test.indices, test.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
