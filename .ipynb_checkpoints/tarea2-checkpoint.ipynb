{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "Integrantes:\n",
    "* Juan Maulén \n",
    "* Pedro Pérez\n",
    "* Tomás Rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:02:17.697434Z",
     "start_time": "2020-07-05T05:02:15.990418Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import DatasetFolder\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:02:17.732741Z",
     "start_time": "2020-07-05T05:02:17.709438Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_rotation(im, theta):\n",
    "    theta = random.uniform(*theta)\n",
    "    return im.rotate(theta)\n",
    "\n",
    "def random_flip(im):\n",
    "    if bool(random.getrandbits(1)):\n",
    "        im = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return im\n",
    "    \n",
    "def loader(path):\n",
    "    transformation = ToTensor()\n",
    "    \n",
    "    im = Image.open(path).resize((224, 224))  # escalamiento de la imagen\n",
    "    im = random_flip(im)  # reflexion de la imagen\n",
    "    im = random_rotation(im, (-20, 20))  # rotacion aleatoria de la imagen\n",
    "    \n",
    "    \n",
    "    tensor = transformation(im)  # se transforma la imagen a un tensor\n",
    "    if tensor.shape[0] == 1:\n",
    "        tensor = tensor.repeat(3, 1, 1)\n",
    "    \n",
    "    rand_tensor = (1.5 - 1.2) * torch.rand((3, 224, 224)) + 1.2\n",
    "    return tensor * rand_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('./chest_xray/test/NORMAL/IM-0001-0001.jpeg')\n",
    "%timeit im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "%timeit np.fliplr(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate as sk_rotation\n",
    "%timeit im.rotate(20)\n",
    "im_asarray = np.array(im)\n",
    "%timeit sk_rotation(im_asarray, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:29:15.075045Z",
     "start_time": "2020-07-05T05:29:15.005550Z"
    }
   },
   "outputs": [],
   "source": [
    "train_folder = DatasetFolder('./chest_xray/train', loader=loader, extensions='.jpeg')\n",
    "# distribución real\n",
    "test_folder = DatasetFolder('./chest_xray/test', loader=loader, extensions='.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(train_folder, test_folder):\n",
    "    train_folder_x, train_folder_y = np.unique(train_folder.targets, return_counts=True)\n",
    "    test_folder_x, test_folder_y = np.unique(test_folder.targets, return_counts=True)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar([\"'NORMAL' train\",\"'PNEUMONIA' train\"], \n",
    "            train_folder_y)\n",
    "    plt.bar([\"'NORMAL' test\",\"'PNEUMONIA' test\"], \n",
    "            test_folder_y)\n",
    "\n",
    "    p_normal_train = train_folder_y[0] / train_folder_y.sum()\n",
    "    p_pneumonia_train = train_folder_y[1] / train_folder_y.sum()\n",
    "    p_normal_test = test_folder_y[0] / test_folder_y.sum()\n",
    "    p_pneumonia_test = test_folder_y[1] / test_folder_y.sum()\n",
    "\n",
    "\n",
    "    plt.text(-.1, train_folder_y[0] + 15,\n",
    "             '{:.2f}%'.format(p_normal_train * 100))\n",
    "\n",
    "    plt.text(-.1 + 1, train_folder_y[1] + 15,\n",
    "             '{:.2f}%'.format(p_pneumonia_train * 100))\n",
    "\n",
    "    plt.text(-.1 + 2, test_folder_y[0] + 15,\n",
    "             '{:.2f}%'.format(p_normal_test * 100))\n",
    "\n",
    "    plt.text(-.1 + 3, test_folder_y[1] + 15,\n",
    "             '{:.2f}%'.format(p_pneumonia_test * 100))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T05:02:18.803757Z",
     "start_time": "2020-07-05T05:02:17.912552Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogram(train_folder, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "n_test =  int(len(train_folder) * .2)  \n",
    "n_train = len(train_folder) - n_test\n",
    "conjunto_train, conjunto_val = torch.utils.data.random_split(train_folder, [n_train, n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicarMuestreoDePrueba(torch.utils.data.Sampler):\n",
    "    \n",
    "    def __init__(self, etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        if len(etiquetas_val) != len(indices_val):\n",
    "            etiquetas_val = np.array(etiquetas_val)[indices_val]\n",
    "        self.etiquetas_prueba = np.array(etiquetas_prueba)\n",
    "        self.indices_val = np.array(indices_val)\n",
    "        self.etiquetas_val = np.array(etiquetas_val)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # {'NORMAL': 0, 'PNEUMONIA': 1}\n",
    "        clases_prueba, frecuencias_prueba = np.unique(self.etiquetas_prueba, \n",
    "                                                      return_counts=True)\n",
    "        \n",
    "        p_normal_deseada = frecuencias_prueba[0] / frecuencias_prueba.sum()\n",
    "        \n",
    "        indices_val_0 = self.indices_val[np.where(np.array(self.etiquetas_val)==0)]\n",
    "        indices_val_1 = self.indices_val[np.where(np.array(self.etiquetas_val)==1)]\n",
    "        \n",
    "        n_1 = len(indices_val_1)\n",
    "        n_0 = int(n_1 *p_normal_deseada/(1 - p_normal_deseada))\n",
    "        \n",
    "        indices_val_0 = np.random.choice(indices_val_0, n_0)\n",
    "        \n",
    "        lista_con_indices = indices_val_0.tolist() + indices_val_1.tolist()\n",
    "        return iter(lista_con_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sampler = ReplicarMuestreoDePrueba(test_folder.targets, \n",
    "                                        conjunto_val.indices, \n",
    "                                        conjunto_val.dataset.targets)\n",
    "bs = 4\n",
    "training_sampler = SubsetRandomSampler(conjunto_train.indices)\n",
    "test_sampler = RandomSampler(range(len(test_folder)))\n",
    "train_dl = DataLoader(train_folder, batch_size = bs, sampler = training_sampler)\n",
    "validation_dl = DataLoader(train_folder, batch_size = bs, sampler = val_sampler)\n",
    "test_dl = DataLoader(test_folder, batch_size = bs, sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(4020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,  in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, padding, bias = bias)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xb = self.conv1(x)\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1layer1=nn.Conv2d(3,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1)\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1)\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1)\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1)\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1)\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1)\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*81, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(-1,3,224,224)\n",
    "        xb = F.relu(self.conv1layer1(xb))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capas preentrenadas\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "model_VGG16 = torchvision.models.vgg16(pretrained=True, progress=True)\n",
    "pesos_capa1 = model_VGG16.features[0].weight\n",
    "pesos_capa2 = model_VGG16.features[2].weight\n",
    "pesos_capa1.requires_grad = False\n",
    "pesos_capa2.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1layer1=nn.Conv2d(3,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer1.weight = pesos_capa1\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2.weight = pesos_capa2\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1)\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1)\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1)\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1)\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1)\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1)\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*81, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(-1,3,224,224)\n",
    "        xb = F.relu(self.conv1layer1(xb))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, modo='min', paciencia=5, porcentaje=False, tol=0):\n",
    "        self.modo = modo\n",
    "        self.wait = paciencia\n",
    "        self.perc = porcentaje\n",
    "        self.tol = tol\n",
    "        self.best = None\n",
    "        self.bestep = 0\n",
    "    \n",
    "    def mejor(self, metrica_validacion):\n",
    "        \n",
    "        '''\n",
    "        Retorna True cuando se mejora el mejor valor obtenido en métrica. \n",
    "        En caso contrario retorna False.\n",
    "        '''\n",
    "        \n",
    "        if self.best == None:\n",
    "            self.best = metrica_validacion\n",
    "            return True\n",
    "        if self.perc == False:\n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < self.best - self.tol:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "            else:\n",
    "                if metrica_validacion > self.best + self.tol:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "        else: \n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < (1-self.tol)*self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "            else:\n",
    "                if metrica_validacion > (1+self.tol)*self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "        \n",
    "    \n",
    "    def deberia_parar(self, metrica_validacion):\n",
    "        comp = self.mejor(metrica_validacion)\n",
    "        if not comp and self.bestep == self.wait:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ciclo de entrenamiento\n",
    "from torch import optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = []\n",
    "acurracy = []\n",
    "losses = []\n",
    "model = VGG16DWSep()\n",
    "model.cuda()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_func = F.cross_entropy\n",
    "num_epoch = 20\n",
    "es  = EarlyStopping(modo = 'max')\n",
    "for epoch in range(num_epoch):\n",
    "    #ciclo de entrenamiento\n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "        \n",
    "        outputs = model(images.cuda())\n",
    "        loss = loss_func(outputs.cuda(), labels.long().cuda())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    #ciclo de validación\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(validation_dl):\n",
    "        outputs = model(images.cuda()) \n",
    "        correct += (torch.argmax(outputs, dim=1) == labels.cuda()).float().sum() \n",
    "        total += len(labels)\n",
    "    \n",
    "    metrica_validacion_1 = 100 * correct / total #acurracy\n",
    "    metrica_validacion_1 = metrica_validacion_1.item()\n",
    "    #metrica_validacion_2 = f1_score(labels.detach().cpu().numpy(), outputs.detach().cpu().numpy())\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        print('Epoca:', epoch+1,',', 'metrica:', metrica_validacion_1)\n",
    "    acurracy.append(metrica_validacion_1)\n",
    "    #f1.append(metrica_validacion_2)\n",
    "    if es.deberia_parar(metrica_validacion_1):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ciclo de testeo del modelo\n",
    "for i, (images, labels) in enumerate(test_dl):\n",
    "    outputs = model(images.cuda()) \n",
    "    correct += (torch.argmax(outputs, dim=1) == labels.cuda()).float().sum() \n",
    "    total += len(labels)\n",
    "    valor = 100 * correct / total #acurracy\n",
    "    valor = valor.item()\n",
    "valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('tarea2_model', 'wb')\n",
    "pickle.dump(model, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
