{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "Integrantes:\n",
    "* Juan Maulén \n",
    "* Pedro Pérez\n",
    "* Tomás Rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a83ecc45f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(4020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,  in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, padding, bias = bias)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #xb = x.view(-1,1,244,244)\n",
    "        xb = self.conv1(x)\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super()._init_()\n",
    "        self.conv1layer1=nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1).conv2d\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1).conv2d\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1).conv2d\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1).conv2d\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1).conv2d\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1).conv2d\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1).conv2d\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1).conv2d\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward():\n",
    "        xb = xb.view(-1, 1, 244, 244)\n",
    "        xb = F.relu(self.conv1layer1(xb.float()))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capas preentrenadas\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "model_VGG16 = torchvision.models.vgg16(pretrained=True, progress=True)\n",
    "pesos_capa1 = model_VGG16.features[0].weight\n",
    "pesos_capa2 = model_VGG16.features[2].weight\n",
    "pesos_capa1.requires_grad = False\n",
    "pesos_capa2.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-5.5373e-01,  1.4270e-01,  5.2896e-01],\n",
       "          [-5.8312e-01,  3.5655e-01,  7.6566e-01],\n",
       "          [-6.9022e-01, -4.8019e-02,  4.8409e-01]],\n",
       "\n",
       "         [[ 1.7548e-01,  9.8630e-03, -8.1413e-02],\n",
       "          [ 4.4089e-02, -7.0323e-02, -2.6035e-01],\n",
       "          [ 1.3239e-01, -1.7279e-01, -1.3226e-01]],\n",
       "\n",
       "         [[ 3.1303e-01, -1.6591e-01, -4.2752e-01],\n",
       "          [ 4.7519e-01, -8.2677e-02, -4.8700e-01],\n",
       "          [ 6.3203e-01,  1.9308e-02, -2.7753e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3254e-01,  1.2666e-01,  1.8605e-01],\n",
       "          [-4.2805e-01, -2.4349e-01,  2.4628e-01],\n",
       "          [-2.5066e-01,  1.4177e-01, -5.4864e-03]],\n",
       "\n",
       "         [[-1.4076e-01, -2.1903e-01,  1.5041e-01],\n",
       "          [-8.4127e-01, -3.5176e-01,  5.6398e-01],\n",
       "          [-2.4194e-01,  5.1928e-01,  5.3915e-01]],\n",
       "\n",
       "         [[-3.1432e-01, -3.7048e-01, -1.3094e-01],\n",
       "          [-4.7144e-01, -1.5503e-01,  3.4589e-01],\n",
       "          [ 5.4384e-02,  5.8683e-01,  4.9580e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7715e-01,  5.2149e-01,  9.8740e-03],\n",
       "          [-2.7185e-01, -7.1709e-01,  3.1292e-01],\n",
       "          [-7.5753e-02, -2.2079e-01,  3.3455e-01]],\n",
       "\n",
       "         [[ 3.0924e-01,  6.7071e-01,  2.0546e-02],\n",
       "          [-4.6607e-01, -1.0697e+00,  3.3501e-01],\n",
       "          [-8.0284e-02, -3.0522e-01,  5.4460e-01]],\n",
       "\n",
       "         [[ 3.1572e-01,  4.2335e-01, -3.4976e-01],\n",
       "          [ 8.6354e-02, -4.6457e-01,  1.1803e-02],\n",
       "          [ 1.0483e-01, -1.4584e-01, -1.5765e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 7.7599e-02,  1.2692e-01,  3.2305e-02],\n",
       "          [ 2.2131e-01,  2.4681e-01, -4.6637e-02],\n",
       "          [ 4.6407e-02,  2.8246e-02,  1.7528e-02]],\n",
       "\n",
       "         [[-1.8327e-01, -6.7425e-02, -7.2120e-03],\n",
       "          [-4.8855e-02,  7.0427e-03, -1.2883e-01],\n",
       "          [-6.4601e-02, -6.4566e-02,  4.4235e-02]],\n",
       "\n",
       "         [[-2.2547e-01, -1.1931e-01, -2.3425e-02],\n",
       "          [-9.9171e-02, -1.5143e-02,  9.5385e-04],\n",
       "          [-2.6137e-02,  1.3567e-03,  1.4282e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6520e-02, -3.2225e-02, -3.8450e-03],\n",
       "          [-6.8206e-02, -1.9445e-01, -1.4166e-01],\n",
       "          [-6.9528e-02, -1.8340e-01, -1.7422e-01]],\n",
       "\n",
       "         [[ 4.2781e-02, -6.7529e-02, -7.0309e-03],\n",
       "          [ 1.1765e-02, -1.4958e-01, -1.2361e-01],\n",
       "          [ 1.0205e-02, -1.0393e-01, -1.1742e-01]],\n",
       "\n",
       "         [[ 1.2661e-01,  8.5046e-02,  1.3066e-01],\n",
       "          [ 1.7585e-01,  1.1288e-01,  1.1937e-01],\n",
       "          [ 1.4656e-01,  9.8892e-02,  1.0348e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2176e-02, -1.0766e-01, -2.6388e-01],\n",
       "          [ 2.7957e-01, -3.7416e-02, -2.5471e-01],\n",
       "          [ 3.4872e-01,  3.0041e-02, -5.5898e-02]],\n",
       "\n",
       "         [[ 2.5063e-01,  1.5543e-01, -1.7432e-01],\n",
       "          [ 3.9255e-01,  3.2306e-02, -3.5191e-01],\n",
       "          [ 1.9299e-01, -1.9898e-01, -2.9713e-01]],\n",
       "\n",
       "         [[ 4.6032e-01,  4.3399e-01,  2.8352e-01],\n",
       "          [ 1.6341e-01, -5.8165e-02, -1.9196e-01],\n",
       "          [-1.9521e-01, -4.5630e-01, -4.2732e-01]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super()._init_()\n",
    "        self.conv1layer1=nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer1.weight = pesos_capa1\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2.weight = pesos_capa2\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1).conv2d\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1).conv2d\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1).conv2d\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1).conv2d\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1).conv2d\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1).conv2d\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1).conv2d\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1).conv2d\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward():\n",
    "        xb = xb.view(-1, 1, 244, 244)\n",
    "        xb = F.relu(self.conv1layer1(xb.float()))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, modo='min', paciencia=5, porcentaje=False, tol=0):\n",
    "        self.modo = modo\n",
    "        self.wait = paciencia\n",
    "        self.perc = porcentaje\n",
    "        self.tol = tol\n",
    "        self.best = None\n",
    "        self.bestep = 0\n",
    "    \n",
    "    def mejor(self, metrica_validacion):\n",
    "        \n",
    "        '''\n",
    "        Retorna True cuando empeora la métrica con respecto a la mejor métrica registrada \n",
    "        más que un margen permitido (tol). En caso contrario retorna False.\n",
    "        '''\n",
    "        \n",
    "        if self.best == None:\n",
    "            self.best = metrica_validacion\n",
    "            return False\n",
    "        if self.perc == False:\n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    self.tol = 0\n",
    "                    return False\n",
    "                elif self.best >= metrica_validacion - self.tol:\n",
    "                    return False\n",
    "                else:\n",
    "                    self.tol = metrica_validacion - self.best\n",
    "                    self.bestep += 1\n",
    "                    return True\n",
    "            else:\n",
    "                if metrica_validacion > self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    self.tol = 0\n",
    "                    return False\n",
    "                elif self.best <= metrica_validacion + self.tol:\n",
    "                    return False\n",
    "                else:\n",
    "                    self.tol = self.best - metrica_validacion\n",
    "                    self.bestep += 1\n",
    "                    return True\n",
    "        else: \n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    self.tol = 0\n",
    "                    return False\n",
    "                elif self.tol >= (metrica_validacion - self.best)/self.best:\n",
    "                    return False\n",
    "                else:\n",
    "                    self.tol = (metrica_validacion - self.best)/self.best\n",
    "                    self.bestep += 1\n",
    "                    return True\n",
    "            else:\n",
    "                if metrica_validacion > self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    self.tol = 0\n",
    "                    return False\n",
    "                elif (self.best - metrica_validacion)/self.best <= self.tol:\n",
    "                    return False\n",
    "                else:\n",
    "                    self.tol = (self.best - metrica_validacion)/self.best\n",
    "                    self.bestep += 1\n",
    "                    return True\n",
    "        \n",
    "    \n",
    "    def deberia_parar(self, metrica_validacion):\n",
    "        comp = mejor(self, metrica_validacion)\n",
    "        if comp and self.bestep == self.wait:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ciclo de entrenamiento\n",
    "from torch import optim\n",
    "\n",
    "model = VGG16DWSep()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_func = F.cross_entropy\n",
    "num_epoch = 20\n",
    "es  = EarlyStopping()\n",
    "for epoch in range(num_epoch):\n",
    "    #ciclo de entrenamiento\n",
    "    \n",
    "    #ciclo de validación\n",
    "    metrica_validacion #=\n",
    "    if es.deberia_parar(metrica_validacion):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
