{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "Integrantes:\n",
    "* Juan José Maulén \n",
    "* Pedro Pérez\n",
    "* Tomás Rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import DatasetFolder\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation(im, theta):\n",
    "    theta = random.uniform(*theta)\n",
    "    return im.rotate(theta)\n",
    "\n",
    "def random_flip(im):\n",
    "    if bool(random.getrandbits(1)):\n",
    "        im = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return im\n",
    "    \n",
    "def loader(path):\n",
    "    transformation = ToTensor()\n",
    "    \n",
    "    im = Image.open(path).resize((224, 224))  # escalamiento de la imagen\n",
    "    im = random_flip(im)  # reflexion de la imagen\n",
    "    im = random_rotation(im, (-20, 20))  # rotacion aleatoria de la imagen\n",
    "    \n",
    "    \n",
    "    tensor = transformation(im)  # se transforma la imagen a un tensor\n",
    "    if tensor.shape[0] == 1:\n",
    "        tensor = tensor.repeat(3, 1, 1)\n",
    "    \n",
    "    rand_tensor = (1.5 - 1.2) * torch.rand((3, 224, 224)) + 1.2\n",
    "    return tensor * rand_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('./chest_xray/test/NORMAL/IM-0001-0001.jpeg')\n",
    "%timeit im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "%timeit np.fliplr(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate as sk_rotation\n",
    "%timeit im.rotate(20)\n",
    "im_asarray = np.array(im)\n",
    "%timeit sk_rotation(im_asarray, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrays = glob.glob('./chest_xray/test/PNEUMONIA/*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xrays(n, paths, *args, **kwargs):\n",
    "    im2use = random.choices(paths, k=n)\n",
    "    fig, ax = plt.subplots(2, n, *args, **kwargs)\n",
    "    fig.tight_layout(h_pad=-20.0*n/3)\n",
    "    for i, path in enumerate(im2use):\n",
    "        ax[0, i].imshow(Image.open(path), 'gray')\n",
    "        ax[0, i].set_title('Imagen {} original'.format(i + 1))\n",
    "    for i, path in enumerate(im2use):\n",
    "        ax[1, i].imshow(loader(path).sum(axis=0), 'gray')\n",
    "        ax[1, i].set_title('Imagen {} al cargar'.format(i + 1))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_xrays(3, xrays, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = DatasetFolder('./chest_xray/train', loader=loader, extensions='.jpeg')\n",
    "# distribución real\n",
    "test_folder = DatasetFolder('./chest_xray/test', loader=loader, extensions='.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(train_folder, test_folder):\n",
    "    train_folder_x, train_folder_y = np.unique(train_folder.targets, return_counts=True)\n",
    "    test_folder_x, test_folder_y = np.unique(test_folder.targets, return_counts=True)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar([\"'NORMAL' train\",\"'PNEUMONIA' train\"], \n",
    "            train_folder_y)\n",
    "    plt.bar([\"'NORMAL' test\",\"'PNEUMONIA' test\"], \n",
    "            test_folder_y)\n",
    "\n",
    "    p_normal_train = train_folder_y[0] / train_folder_y.sum()\n",
    "    p_pneumonia_train = train_folder_y[1] / train_folder_y.sum()\n",
    "    p_normal_test = test_folder_y[0] / test_folder_y.sum()\n",
    "    p_pneumonia_test = test_folder_y[1] / test_folder_y.sum()\n",
    "\n",
    "\n",
    "    plt.text(-.1, train_folder_y[0] + 15,\n",
    "             '{:.2f}%'.format(p_normal_train * 100))\n",
    "\n",
    "    plt.text(-.1 + 1, train_folder_y[1] + 15,\n",
    "             '{:.2f}%'.format(p_pneumonia_train * 100))\n",
    "\n",
    "    plt.text(-.1 + 2, test_folder_y[0] + 15,\n",
    "             '{:.2f}%'.format(p_normal_test * 100))\n",
    "\n",
    "    plt.text(-.1 + 3, test_folder_y[1] + 15,\n",
    "             '{:.2f}%'.format(p_pneumonia_test * 100))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(train_folder, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "n_test =  int(len(train_folder) * .2)  \n",
    "n_train = len(train_folder) - n_test\n",
    "conjunto_train, conjunto_val = torch.utils.data.random_split(train_folder, [n_train, n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicarMuestreoDePrueba(torch.utils.data.Sampler):\n",
    "    \n",
    "    def __init__(self, etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        if len(etiquetas_val) != len(indices_val):\n",
    "            etiquetas_val = np.array(etiquetas_val)[indices_val]\n",
    "        self.etiquetas_prueba = np.array(etiquetas_prueba)\n",
    "        self.indices_val = np.array(indices_val)\n",
    "        self.etiquetas_val = np.array(etiquetas_val)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # {'NORMAL': 0, 'PNEUMONIA': 1}\n",
    "        clases_prueba, frecuencias_prueba = np.unique(self.etiquetas_prueba, \n",
    "                                                      return_counts=True)\n",
    "        \n",
    "        p_normal_deseada = frecuencias_prueba[0] / frecuencias_prueba.sum()\n",
    "        \n",
    "        indices_val_0 = self.indices_val[np.where(np.array(self.etiquetas_val)==0)]\n",
    "        indices_val_1 = self.indices_val[np.where(np.array(self.etiquetas_val)==1)]\n",
    "        \n",
    "        n_1 = len(indices_val_1)\n",
    "        n_0 = int(n_1 *p_normal_deseada/(1 - p_normal_deseada))\n",
    "        \n",
    "        indices_val_0 = np.random.choice(indices_val_0, n_0)\n",
    "        \n",
    "        lista_con_indices = indices_val_0.tolist() + indices_val_1.tolist()\n",
    "        return iter(lista_con_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sampler = ReplicarMuestreoDePrueba(test_folder.targets, \n",
    "                                        conjunto_val.indices, \n",
    "                                        conjunto_val.dataset.targets)\n",
    "bs = 4\n",
    "training_sampler = SubsetRandomSampler(conjunto_train.indices)\n",
    "test_sampler = RandomSampler(range(len(test_folder)))\n",
    "train_dl = DataLoader(train_folder, batch_size = bs, sampler = training_sampler)\n",
    "validation_dl = DataLoader(train_folder, batch_size = bs, sampler = val_sampler)\n",
    "test_dl = DataLoader(test_folder, batch_size = bs, sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(4020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,  in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, padding, bias = bias)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xb = self.conv1(x)\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1layer1=nn.Conv2d(3,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1)\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1)\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1)\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1)\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1)\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1)\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*81, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(-1,3,224,224)\n",
    "        xb = F.relu(self.conv1layer1(xb))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capas preentrenadas\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "model_VGG16 = torchvision.models.vgg16(pretrained=True, progress=True)\n",
    "pesos_capa1 = model_VGG16.features[0].weight\n",
    "pesos_capa2 = model_VGG16.features[2].weight\n",
    "pesos_capa1.requires_grad = False\n",
    "pesos_capa2.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1layer1=nn.Conv2d(3,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer1.weight = pesos_capa1\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2.weight = pesos_capa2\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1)\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1)\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1)\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1)\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1)\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1)\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*81, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(-1,3,224,224)\n",
    "        xb = F.relu(self.conv1layer1(xb))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, modo='min', paciencia=5, porcentaje=False, tol=0):\n",
    "        self.modo = modo\n",
    "        self.wait = paciencia\n",
    "        self.perc = porcentaje\n",
    "        self.tol = tol\n",
    "        self.best = None\n",
    "        self.bestep = 0\n",
    "    \n",
    "    def mejor(self, metrica_validacion):\n",
    "        \n",
    "        '''\n",
    "        Retorna True cuando se mejora el mejor valor obtenido en métrica. \n",
    "        En caso contrario retorna False.\n",
    "        '''\n",
    "        \n",
    "        if self.best == None:\n",
    "            self.best = metrica_validacion\n",
    "            return True\n",
    "        if self.perc == False:\n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < self.best - self.tol:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "            else:\n",
    "                if metrica_validacion > self.best + self.tol:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "        else: \n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < (1-self.tol)*self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "            else:\n",
    "                if metrica_validacion > (1+self.tol)*self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "        \n",
    "    \n",
    "    def deberia_parar(self, metrica_validacion):\n",
    "        comp = self.mejor(metrica_validacion)\n",
    "        if not comp and self.bestep == self.wait:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ciclo de entrenamiento\n",
    "from torch import optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = []\n",
    "acurracy = []\n",
    "losses = []\n",
    "model = VGG16DWSep()\n",
    "model.cuda()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_func = F.cross_entropy\n",
    "num_epoch = 20\n",
    "es  = EarlyStopping(modo = 'max')\n",
    "for epoch in range(num_epoch):\n",
    "    #ciclo de entrenamiento\n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "        \n",
    "        outputs = model(images.cuda())\n",
    "        loss = loss_func(outputs.cuda(), labels.long().cuda())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    #ciclo de validación\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(validation_dl):\n",
    "        outputs = model(images.cuda()) \n",
    "        correct += (torch.argmax(outputs, dim=1) == labels.cuda()).float().sum() \n",
    "        total += len(labels)\n",
    "    \n",
    "    metrica_validacion_1 = 100 * correct / total #acurracy\n",
    "    metrica_validacion_1 = metrica_validacion_1.item()\n",
    "    #metrica_validacion_2 = f1_score(labels.detach().cpu().numpy(), outputs.detach().cpu().numpy())\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        print('Epoca:', epoch+1,',', 'metrica:', metrica_validacion_1)\n",
    "    acurracy.append(metrica_validacion_1)\n",
    "    #f1.append(metrica_validacion_2)\n",
    "    if es.deberia_parar(metrica_validacion_1):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ciclo de testeo del modelo\n",
    "for i, (images, labels) in enumerate(test_dl):\n",
    "    outputs = model(images.cuda()) \n",
    "    correct += (torch.argmax(outputs, dim=1) == labels.cuda()).float().sum() \n",
    "    total += len(labels)\n",
    "    valor = 100 * correct / total #acurracy\n",
    "    valor = valor.item()\n",
    "valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('tarea2_model', 'wb')\n",
    "pickle.dump(model, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importa la imagen y se le hacen las transformaciones correspondientes\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(299),\n",
    "                                transforms.CenterCrop(299),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "img=Image.open('P3_example.jpg').convert('RGB') \n",
    "img_t=transform(img)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Imagen original')\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Imagen transformada')\n",
    "plt.imshow(transforms.ToPILImage()(img_t))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "#Se carga y entrena la red Inception V3\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'inception_v3', pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hacen las predicciones para la imagen de control\n",
    "#Se imprimen las diez primeras predicciones y se grafican los puntajes de los \n",
    "#5 primeros\n",
    "\n",
    "input_batch = img_t.unsqueeze(0) \n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "      preds = model(input_batch)\n",
    "\n",
    "\n",
    "print('Predicted:', decode_predictions(preds.cpu().detach().numpy(), top=10))\n",
    "\n",
    "\n",
    "labels=[]\n",
    "scores=np.zeros(5)\n",
    "for i in range(5):\n",
    "    labels.append(decode_predictions(preds.cpu().detach().numpy(), top=10)[0][i][1])\n",
    "    scores[i]=decode_predictions(preds.cpu().detach().numpy(), top=10)[0][i][2]\n",
    "\n",
    "plt.bar(range(5), scores, edgecolor='black')\n",
    "\n",
    "plt.xticks(range(5), labels, rotation=60)\n",
    "plt.title(\"Puntajes obtenidos por las 5 clases más probables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "#Crea el slic pedido, arreglo 299 x 299\n",
    "slic_1=slic(transforms.ToPILImage()(img_t),n_segments=80)\n",
    "n_cat=np.amax(slic_1)  + 1 #Parten desde la categoria 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage import segmentation\n",
    "#Visualizacion del Slic\n",
    "\n",
    "slic = slic(img, n_segments=80)\n",
    "\n",
    "plt.figure\n",
    "plt.imshow(segmentation.mark_boundaries(img, slic))\n",
    "plt.title('Visualización de super-pixeles')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear perturbaciones\n",
    "\n",
    "n_pert=1000\n",
    "\n",
    "perturbaciones={} #Diccionario con las perturbaciones\n",
    "\n",
    "for i in range (n_pert):\n",
    "    perturbaciones[i]=np.random.binomial(size=n_cat, n=1, p= 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crean las imagenes perturbadas, se guardan en el diccionario imgs_pert\n",
    "\n",
    "\n",
    "imgs_pert={}\n",
    "img_t_copy=img_t.detach().numpy()\n",
    "\n",
    "\n",
    "#Para cada perturbacion, se le agrega una nueva capa a la imagen de control. \n",
    "#Esta nueva capa tiene el arreglo con los clusters, y en el caso que el cluster\n",
    "#correspondiente tenga un 0 en la perturbación, se reemplaza el valor por un 999.\n",
    "#En la imagen de control, si la nueva capa tiene un 999, se reemplazan todos los pixeles\n",
    "#correspondientes por un 0.\n",
    "\n",
    "\n",
    "for i in range(n_pert):\n",
    "    aux=np.copy(slic_1)\n",
    "    pert=perturbaciones[i]\n",
    "    for j in range(n_cat):\n",
    "        if pert[j]==0:\n",
    "            aux[aux==j]=999\n",
    "    img_pert=np.zeros((4,299,299))\n",
    "    img_pert[0,:,:]=aux\n",
    "    img_pert[[1,2,3],:,:]=img_t_copy\n",
    "    img_pert[1][img_pert[0]==999]=0\n",
    "    img_pert[2][img_pert[0]==999]=0\n",
    "    img_pert[3][img_pert[0]==999]=0\n",
    "    imgs_pert[i]=torch.tensor(img_pert[[1,2,3]],dtype=torch.float32)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se muestran 3 imagenes perturbadas\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
    "plt.suptitle('Visualización de imágenes perturbadas ',fontsize=20,x=0.5, y=1.05)\n",
    "for ax, i in zip(axs, np.random.randint(1,1000,3)):\n",
    "    ax.imshow(transforms.ToPILImage()(imgs_pert[i]))\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hacen las predicciones usando InceptionV3 para cada imagen perturbada, \n",
    "#y se forma el arreglo y, con un 1 si se clasifico como \"labrador_retriever\"\n",
    "#y 0 si no\n",
    "\n",
    "y=np.zeros(n_pert)\n",
    "clas_expected=labels[0]\n",
    "\n",
    "\n",
    "for i in range(n_pert):\n",
    "    input_batch=torch.unsqueeze(imgs_pert[i],0)\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_batch)\n",
    "\n",
    "\n",
    "    clas=decode_predictions(preds.cpu().detach().numpy())[0][0][1]\n",
    "    if clas== clas_expected:\n",
    "        y[i]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calcula la distancia coseno y los pesos asociados a cada vector de perturbaciones vs. \n",
    "#el vector de perturbacion de la imagen de control (un vector de 1s)\n",
    "from numpy import linalg as LA\n",
    "\n",
    "sigma=0.25\n",
    "dist=np.zeros(n_pert)\n",
    "\n",
    "for i in range(n_pert):\n",
    "    dist[i]=1 - np.dot(perturbaciones[i],np.ones(n_cat))/(LA.norm(perturbaciones[i])*LA.norm(np.ones(n_cat)))\n",
    "\n",
    "pi=np.exp(-np.square(dist)/sigma**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se genera el conjunto de entrenamiento y se hace la regresion logistica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "D_p = np.zeros((n_pert,n_cat))\n",
    "\n",
    "for i in range(n_pert):\n",
    "    D_p[i]=perturbaciones[i]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(D_p,y,sample_weight=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se obtienen los coeficientes del clasificador anterior\n",
    "coef=np.std(D_p, 0)*clf.coef_\n",
    "\n",
    "coef=coef.flatten()\n",
    "\n",
    "#Se obtienen los 10 coeficientes con mayor valor\n",
    "n=10\n",
    "idx = (-coef).argsort()[:n]\n",
    "#coef[idx]\n",
    "\n",
    "plt.bar(range(n), coef[idx], edgecolor='black')\n",
    "plt.xticks(range(n), idx, rotation=60)\n",
    "plt.title(\"10 mayores coeficientes para superpixeles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se genera una visualización de la imagen considerando solo los superpixeles \n",
    "#más importantes, encontrados en el paso anterior\n",
    "img_t_copy=img_t.detach().numpy()\n",
    "aux=np.copy(slic_1)\n",
    "\n",
    "for i in range(n):\n",
    "    aux[aux==idx[i]]=999\n",
    "\n",
    "img_new=np.zeros((4,299,299))\n",
    "img_new[0,:,:]=aux\n",
    "img_new[[1,2,3],:,:]=img_t_copy\n",
    "img_new[1][img_new[0] != 999]=0\n",
    "img_new[2][img_new[0] != 999]=0\n",
    "img_new[3][img_new[0] != 999]=0\n",
    "\n",
    "img_new=torch.tensor(img_new[[1,2,3]],dtype=torch.float32)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(transforms.ToPILImage()(img_new))\n",
    "plt.title('10 superpixeles más importantes usando SLIC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para hacer la clusterización, necesitamos la imagen en escala de grises\n",
    "\n",
    "\n",
    "\n",
    "img_gray=transforms.Resize(299)(img)\n",
    "img_gray=transforms.CenterCrop(299)(img_gray)\n",
    "img_gray = np.mean(np.asarray(img_gray), axis=2, dtype=np.int32) #Se pasa a grises\n",
    "img_gray = transforms.ToPILImage()(img_gray) \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_gray, cmap=\"Greys_r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se genera la matriz de entrenamiento, tiene 299*299 filas. \n",
    "#Cada fila tiene un arreglo de 3 dimensiones, donde la primera y la segunda\n",
    "#representan la fila y columna de un pixel de la representación matricial de \n",
    "#la imagen, y la tercera es la intensidad de la escala de grises.\n",
    "\n",
    "\n",
    "X_train=np.zeros((299*299,3))\n",
    "\n",
    "for i in range(299):\n",
    "    for j in range(299):\n",
    "        row=np.zeros(3)\n",
    "        row=([i , j, np.asarray(img_gray)[i][j] ])\n",
    "        X_train[i*299 + j]=row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "#Clusterizaremos la matriz usando MiniBatchKMeans\n",
    "\n",
    "MiniBatchKMeans = MiniBatchKMeans(n_clusters=40,random_state=20).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiniBatchKMeans_matrix=MiniBatchKMeans.labels_.reshape((299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "#Se clusteriza usando GaussianMixture\n",
    "\n",
    "Gaussian = GaussianMixture(n_components=40, random_state=20).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaussian_matrix = Gaussian.predict(X_train).reshape(299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se replica el esquema LIME anterior, pero cambiando la matrix slic_1 \n",
    "#usada anteriormente por las matrices nuevas después de Clusterizar\n",
    "from numpy import linalg as LA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "img_t_copy=img_t.detach().numpy()\n",
    "clas_expected=labels[0]\n",
    "\n",
    "def Lime(n_pert,matrix,cluster_method, net='InceptionV3', sigma=0.25, n_top=10):\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    imgs_pert={}\n",
    "\n",
    "    n_cat=np.amax(matrix)+1\n",
    "    perturbaciones={} #Diccionario con las perturbaciones\n",
    "\n",
    "    for i in range (n_pert):\n",
    "        perturbaciones[i]=np.random.binomial(size=n_cat, n=1, p= 0.5)\n",
    "\n",
    "\n",
    "  \n",
    "    for i in range(n_pert):\n",
    "        aux=np.copy(matrix)\n",
    "        pert=perturbaciones[i]\n",
    "        for j in range(n_cat):\n",
    "            if pert[j]==0:\n",
    "                aux[aux==j]=999\n",
    "        img_pert=np.zeros((4,299,299))\n",
    "        img_pert[0,:,:]=aux\n",
    "        img_pert[[1,2,3],:,:]=img_t_copy\n",
    "        img_pert[1][img_pert[0]==999]=0\n",
    "        img_pert[2][img_pert[0]==999]=0\n",
    "        img_pert[3][img_pert[0]==999]=0\n",
    "        imgs_pert[i]=torch.tensor(img_pert[[1,2,3]],dtype=torch.float32)\n",
    "\n",
    "    y=np.zeros(n_pert)\n",
    "  \n",
    "    for i in range(n_pert):\n",
    "        input_batch=torch.unsqueeze(imgs_pert[i],0)\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = input_batch.to('cuda')\n",
    "            model.to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(input_batch)\n",
    "\n",
    "\n",
    "        clas=decode_predictions(preds.cpu().detach().numpy())[0][0][1]\n",
    "        if clas== clas_expected:\n",
    "            y[i]=1\n",
    "  \n",
    "    dist=np.zeros(n_pert)\n",
    "\n",
    "    for i in range(n_pert):\n",
    "        dist[i]=1 - np.dot(perturbaciones[i],np.ones(n_cat))/(LA.norm(perturbaciones[i])*LA.norm(np.ones(n_cat)))\n",
    "\n",
    "    pi=np.exp(-np.square(dist)/sigma**2)\n",
    "\n",
    "    D_p = np.zeros((n_pert,n_cat))\n",
    "\n",
    "    for i in range(n_pert):\n",
    "        D_p[i]=perturbaciones[i]\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(D_p,y,sample_weight=pi)\n",
    "\n",
    "    coef=np.std(D_p, 0)*clf.coef_\n",
    "    coef=coef.flatten()\n",
    "\n",
    " \n",
    "    idx = (-coef).argsort()[:n_top]\n",
    "\n",
    "    aux=np.copy(matrix)\n",
    "\n",
    "    for i in range(n_top):\n",
    "        aux[aux==idx[i]]=999\n",
    "\n",
    "    img_new=np.zeros((4,299,299))\n",
    "    img_new[0,:,:]=aux\n",
    "    img_new[[1,2,3],:,:]=img_t_copy\n",
    "    img_new[1][img_new[0] != 999]=0\n",
    "    img_new[2][img_new[0] != 999]=0\n",
    "    img_new[3][img_new[0] != 999]=0\n",
    "\n",
    "    img_new=torch.tensor(img_new[[1,2,3]],dtype=torch.float32)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(transforms.ToPILImage()(img_new))\n",
    "    plt.title(str(n_top)+' superpixeles más importantes usando '+cluster_method)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lime(1000,MiniBatchKMeans_matrix,'MiniBatchKMeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lime(1000,Gaussian_matrix,'Gaussian Mixture')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
