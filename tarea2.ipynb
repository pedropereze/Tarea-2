{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "Integrantes:\n",
    "* Juan Maulén \n",
    "* Pedro Pérez\n",
    "* Tomás Rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a98e4655b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(4020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DWSepConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,  in_channels, out_channels, kernel_size, padding, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, padding, bias = bias)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xb = self.conv1(x)\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super()._init_()\n",
    "        self.conv1layer1=nn.Conv2d(3,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1)\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1)\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1)\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1)\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1)\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1)\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward():\n",
    "        xb = xb.view(-1, 3, 224, 224)\n",
    "        xb = F.relu(self.conv1layer1(xb.float()))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capas preentrenadas\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "model_VGG16 = torchvision.models.vgg16(pretrained=True, progress=True)\n",
    "pesos_capa1 = model_VGG16.features[0].weight\n",
    "pesos_capa2 = model_VGG16.features[2].weight\n",
    "pesos_capa1.requires_grad = False\n",
    "pesos_capa2.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16DWSep(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1layer1=nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer1.weight = pesos_capa1\n",
    "        self.conv1layer2=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "        self.conv1layer2.weight = pesos_capa2\n",
    "        self.maxpool2d1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv2layer1=DWSepConv2d(64,128,3,1)\n",
    "        self.conv2layer2=DWSepConv2d(128,128,3,1)\n",
    "        self.maxpool2d2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv1=DWSepConv2d(128,256,3,1)\n",
    "        self.batchnorm1=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2=DWSepConv2d(256,256,3,1)\n",
    "        self.batchnorm2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3=DWSepConv2d(256,512,3,1)\n",
    "        self.maxpool2d3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.conv4=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm4=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5=DWSepConv2d(512,512,3,1)\n",
    "        self.batchnorm5=nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv6=DWSepConv2d(512,512,3,1)\n",
    "        self.maxpool2d6=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 1024)\n",
    "        self.dropout1=nn.Dropout(.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2=nn.Dropout(.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "    \n",
    "       \n",
    "    def forward():\n",
    "        xb = xb.view(-1, 3, 224, 224)\n",
    "        xb = F.relu(self.conv1layer1(xb.float()))\n",
    "        xb = F.relu(self.conv1layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2layer1(xb))\n",
    "        xb = F.relu(self.conv2layer2(xb))\n",
    "        xb = F.relu(self.maxpool2d2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.batchnorm1(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.batchnorm2(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.relu(self.maxpool2d3(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv4(xb))\n",
    "        xb = F.relu(self.batchnorm4(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv5(xb))\n",
    "        xb = F.relu(self.batchnorm5(xb))\n",
    "        \n",
    "        xb = F.relu(self.conv6(xb))\n",
    "        xb = F.relu(self.maxpool2d6(xb))\n",
    "        \n",
    "        xb = F.relu(self.flatten(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc1(xb))\n",
    "        xb = F.relu(self.dropout1(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc2(xb))\n",
    "        xb = F.relu(self.dropout2(xb))\n",
    "        \n",
    "        xb = F.relu(self.fc3(xb))\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, modo='min', paciencia=5, porcentaje=False, tol=0):\n",
    "        self.modo = modo\n",
    "        self.wait = paciencia\n",
    "        self.perc = porcentaje\n",
    "        self.tol = tol\n",
    "        self.best = None\n",
    "        self.bestep = 0\n",
    "    \n",
    "    def mejor(self, metrica_validacion):\n",
    "        \n",
    "        '''\n",
    "        Retorna True cuando se mejora el mejor valor obtenido en métrica. \n",
    "        En caso contrario retorna False.\n",
    "        '''\n",
    "        \n",
    "        if self.best == None:\n",
    "            self.best = metrica_validacion\n",
    "            return True\n",
    "        if self.perc == False:\n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < self.best - self.tol:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "            else:\n",
    "                if metrica_validacion > self.best + self.tol:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "        else: \n",
    "            if self.modo == 'min':\n",
    "                if metrica_validacion < (1-self.tol)*self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "            else:\n",
    "                if metrica_validacion > (1+self.tol)*self.best:\n",
    "                    self.best = metrica_validacion\n",
    "                    self.bestep = 0\n",
    "                    return True\n",
    "                else:\n",
    "                    self.bestep += 1\n",
    "                    return False\n",
    "        \n",
    "    \n",
    "    def deberia_parar(self, metrica_validacion):\n",
    "        comp = self.mejor(metrica_validacion)\n",
    "        if not comp and self.bestep == self.wait:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ciclo de entrenamiento\n",
    "from torch import optim\n",
    "\n",
    "tl = []\n",
    "losses = []\n",
    "model = VGG16DWSep()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_func = F.cross_entropy\n",
    "num_epoch = 20\n",
    "es  = EarlyStopping()\n",
    "for epoch in range(num_epoch):\n",
    "    #ciclo de entrenamiento\n",
    "    for i, (images, labels) in enumerate(tl):\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Backprop and perform Adam optimisation\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    #ciclo de validación\n",
    "    metrica_validacion = 0\n",
    "    if es.deberia_parar(metrica_validacion):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
